{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tic_tac_toe_model():\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.matriz = np.full((n,n),0,dtype=int)\n",
    "    \n",
    "    def reset_matrix(self):\n",
    "        self.matriz = np.full((self.n,self.n),0,dtype=int)\n",
    "\n",
    "    def print_game(self):\n",
    "        matriz = self.matriz\n",
    "        substituicoes = {1: \"X\", 2: \"O\", 0:' '}\n",
    "        for linha in matriz:\n",
    "            linha_formatada = [str(substituicoes.get(valor, valor)) for valor in linha]\n",
    "            print(\" | \".join(linha_formatada))\n",
    "            print(\"-\" * 9)\n",
    "    \n",
    "\n",
    "    def number_ij(self, number):\n",
    "        i,j = np.unravel_index(number, self.matriz.shape)\n",
    "        return i,j\n",
    "    \n",
    "    \n",
    "    def get_avaible_moves(self):\n",
    "        avaible_moves = np.ravel_multi_index(np.where(self.matriz == 0), self.matriz.shape)\n",
    "        return list(avaible_moves)\n",
    "\n",
    "    def get_random_move(self, piece):\n",
    "        possible_move_i, possible_move_j = np.where(self.matriz == 0)\n",
    "        if possible_move_j.shape[0] > 0:  # Verifica se há movimentos possíveis\n",
    "            index = random.randint(0, possible_move_j.shape[0] - 1)  # Correção aqui\n",
    "            self.move(possible_move_i[index], possible_move_j[index], piece)\n",
    "\n",
    "\n",
    "\n",
    "    def move(self,index_i,index_j,piece):\n",
    "        if self.matriz[index_i][index_j] == 0:\n",
    "            self.matriz[index_i][index_j] = piece\n",
    "        \n",
    "    \n",
    "    def reward_piece(self,piece):\n",
    "        w = self.check_win()\n",
    "        if w != 4 :\n",
    "            if w!=3:\n",
    "                if w == piece:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return -1\n",
    "            \n",
    "        return 0.1\n",
    "          \n",
    "    def check_win(self):\n",
    "        state = False\n",
    "        win_piece = -1\n",
    "        value_counts_diagonal = np.unique(self.matriz.diagonal())\n",
    "        value_counts_diagonal2  = np.unique(np.fliplr(self.matriz).diagonal())\n",
    "        if value_counts_diagonal.shape[0] == 1 and value_counts_diagonal[0] !=0:\n",
    "            state=True     \n",
    "            win_piece = value_counts_diagonal[0] \n",
    "            return win_piece          \n",
    "        if value_counts_diagonal2.shape[0] == 1 and value_counts_diagonal2[0] !=0:\n",
    "            state=True    \n",
    "            win_piece = value_counts_diagonal2[0]   \n",
    "            return win_piece         \n",
    "\n",
    "        for i in range(0,self.n):\n",
    "            value_counts_linha = np.unique(self.matriz[i,:])\n",
    "            value_counts_coluna = np.unique(self.matriz[:,i])\n",
    "            \n",
    "            if value_counts_linha.shape[0] == 1 and value_counts_linha[0] != 0 :\n",
    "                state=True\n",
    "                win_piece = value_counts_linha[0]\n",
    "                break\n",
    "            if value_counts_coluna.shape[0] == 1 and value_counts_coluna[0] != 0:\n",
    "                state=True\n",
    "                win_piece = value_counts_coluna[0]\n",
    "                break\n",
    "            \n",
    "        velha = np.where(self.matriz == 0)\n",
    "        \n",
    "        if state:\n",
    "            return win_piece\n",
    "        if velha[0].shape[0] == 0: \n",
    "            return 3\n",
    "        else:\n",
    "            return 4      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QlearningAgent():\n",
    "    def __init__(self, alpha, epsilon, discount_factor):\n",
    "        self.q_table = {}\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.discount_factor = discount_factor\n",
    "\n",
    "\n",
    "    def print_q_values(self):\n",
    "        for key in self.q_table.keys():\n",
    "            print(f\"Key {key} Q-value{self.q_table[key]}\")\n",
    "\n",
    "            \n",
    "    def get_q_value(self, state, action, piece):\n",
    "        state_tuple = tuple(state.flatten())\n",
    "        if (state_tuple, action,piece) not in self.q_table:\n",
    "            self.q_table[(state_tuple, action, piece)] = 0.0\n",
    "\n",
    "        return self.q_table[(state_tuple, action, piece)]\n",
    "\n",
    "    def choose_move(self, state, available_moves, piece):\n",
    "        q_values = []\n",
    "        for action in available_moves:\n",
    "            q_values.append(self.get_q_value(state, action, piece))\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return random.choice(available_moves)\n",
    "        else:\n",
    "            max_q_value = max(q_values)\n",
    "            if q_values.count(max_q_value) > 1:\n",
    "                best_moves = [i for i in range(len(available_moves)) if q_values[i] == max_q_value]\n",
    "                i = random.choice(best_moves)\n",
    "            else:\n",
    "                i = q_values.index(max_q_value)\n",
    "            return available_moves[i]\n",
    "\n",
    "    def update_q_value(self, state, action, piece, reward, next_state, next_moves):\n",
    "        next_q_values = []\n",
    "        for next_action in next_moves:\n",
    "            next_q_values.append(self.get_q_value(next_state, next_action, piece))\n",
    "        \n",
    "        max_next_q = max(next_q_values) if next_q_values else 0.0\n",
    "        state_tuple = tuple(state.flatten())\n",
    "\n",
    "        self.q_table[(state_tuple, action, piece)] += self.alpha * (reward + self.discount_factor * max_next_q - self.q_table[(state_tuple, action, piece)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train():\n",
    "    def __init__(self, tic_tac_toe: tic_tac_toe_model, q_agent: QlearningAgent):\n",
    "        self.board = tic_tac_toe\n",
    "        self.q_agent = q_agent\n",
    "    \n",
    "    \n",
    "    def play_one_game(self, piece):\n",
    "        game_over = False\n",
    "        win_piece = 0\n",
    "        self.board.reset_matrix()\n",
    "        if piece == 1:\n",
    "            piece_enemy = 2\n",
    "            while not game_over:\n",
    "                w = self.board.check_win()\n",
    "                if w != 4:\n",
    "                    win_piece = w\n",
    "                    break\n",
    "                state = self.board.matriz.copy()\n",
    "                avaible_moves = self.board.get_avaible_moves()\n",
    "                action = self.q_agent.choose_move(state,avaible_moves,piece)\n",
    "                i, j = self.board.number_ij(action)\n",
    "                self.board.move(i,j,piece)\n",
    "                if w != 4:\n",
    "                    win_piece = w\n",
    "                    break\n",
    "                self.board.get_random_move(piece_enemy)\n",
    "                next_moves = self.board.get_avaible_moves()\n",
    "                next_state = self.board.matriz.copy()\n",
    "                reward = self.board.reward_piece(piece)\n",
    "               \n",
    "                self.q_agent.update_q_value(state,action,piece,reward,next_state,next_moves)\n",
    "                \n",
    "            return win_piece\n",
    "        else:\n",
    "            piece_enemy = 1\n",
    "            while not game_over:\n",
    "                w = self.board.check_win()\n",
    "                \n",
    "                self.board.get_random_move(piece_enemy)\n",
    "                if w != 4:\n",
    "                    win_piece = w\n",
    "                    break\n",
    "                \n",
    "                state = self.board.matriz.copy()\n",
    "                avaible_moves = self.board.get_avaible_moves()\n",
    "                action = self.q_agent.choose_move(state,avaible_moves,piece)\n",
    "                i, j = self.board.number_ij(action)\n",
    "                self.board.move(i,j,piece)\n",
    "                if w != 4:\n",
    "                    win_piece = w\n",
    "                    break\n",
    "                \n",
    "                self.board.get_random_move(piece_enemy)\n",
    "\n",
    "                if w != 4:\n",
    "                    win_piece = w\n",
    "                    break\n",
    "                \n",
    "                next_moves = self.board.get_avaible_moves()\n",
    "                next_state = self.board.matriz.copy()\n",
    "                reward = self.board.reward_piece(piece)\n",
    "               \n",
    "                self.q_agent.update_q_value(state,action,piece,reward,next_state,next_moves)\n",
    "                \n",
    "            return win_piece\n",
    "            \n",
    "    def play_ia_vs_ia(self):\n",
    "        game_over = False\n",
    "        self.board.reset_matrix()\n",
    "        ia_x = 1\n",
    "        ia_o = 2\n",
    "        while not game_over:\n",
    "            w = self.board.check_win()\n",
    "            if w != 4:\n",
    "                win_piece = w\n",
    "                break\n",
    "            state_x = self.board.matriz.copy()\n",
    "            avaible_moves_x = self.board.get_avaible_moves()\n",
    "            action_x = self.q_agent.choose_move(state_x,avaible_moves_x,ia_x)\n",
    "            i, j = self.board.number_ij(action_x)\n",
    "            self.board.move(i,j,ia_x) # x play\n",
    "            if w != 4:\n",
    "                win_piece = w\n",
    "                break\n",
    "\n",
    "            state_o = self.board.matriz.copy()\n",
    "            avaible_moves_o = self.board.get_avaible_moves()\n",
    "            action_o = self.q_agent.choose_move(state_o,avaible_moves_o,ia_o)\n",
    "            i, j = self.board.number_ij(action_o)\n",
    "            self.board.move(i,j,ia_o) # o play\n",
    "            if w != 4:\n",
    "                win_piece = w\n",
    "                break\n",
    "\n",
    "            #x q_Table update \n",
    "            next_moves_x = self.board.get_avaible_moves()\n",
    "            next_state_x = self.board.matriz.copy()\n",
    "            reward_x = self.board.reward_piece(ia_x)\n",
    "            self.q_agent.update_q_value(state_x,action_x,ia_x,reward_x,next_state_x,next_moves_x)\n",
    "            \n",
    "\n",
    "            #x play again to update q table o\n",
    "            avaible_moves_x = self.board.get_avaible_moves()\n",
    "            action_x = self.q_agent.choose_move(next_state_x,avaible_moves_x,ia_x)# next_state x is the atual state of board\n",
    "            i, j = self.board.number_ij(action_x)\n",
    "            self.board.move(i,j,ia_x) # x play\n",
    "            if w != 4:\n",
    "                win_piece = w\n",
    "                break\n",
    "\n",
    "            #o qtable update\n",
    "            next_moves_o = self.board.get_avaible_moves()\n",
    "            next_state_o = self.board.matriz.copy()\n",
    "            reward_o = self.board.reward_piece(ia_x)\n",
    "            self.q_agent.update_q_value(state_o,action_o,ia_o,reward_o,next_state_o,next_moves_o)\n",
    "\n",
    "        return win_piece\n",
    "    \n",
    "    \n",
    "    def run(self, n):\n",
    "        wins_x = []\n",
    "        wins_o = []\n",
    "        wins_ia = []\n",
    "        print(f'Playing {n} games with X')\n",
    "        for i in tqdm.tqdm(range(0,n)):\n",
    "            wins_x.append(self.play_one_game(piece=1))\n",
    "        print(f'Playing {n} games with O')\n",
    "        for i in tqdm.tqdm(range(0,n)):\n",
    "            wins_o.append(self.play_one_game(piece=2))\n",
    "\n",
    "        print(f'Playing {n} games ia vs ia')\n",
    "        for i in tqdm.tqdm(range(0,n)):\n",
    "            wins_ia.append(self.play_ia_vs_ia())\n",
    "        return wins_x,wins_o, wins_ia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game():\n",
    "    def __init__(self, tic_tac_toe: tic_tac_toe_model, q_agent: QlearningAgent):\n",
    "        self.board = tic_tac_toe\n",
    "        self.q_agent = q_agent\n",
    "    \n",
    "\n",
    "    def ia_vs_ia(self):\n",
    "        game_over = False\n",
    "        self.board.reset_matrix()\n",
    "        while not game_over:\n",
    "            w = self.board.check_win()\n",
    "            if w != 4:\n",
    "                win_piece = w\n",
    "                break\n",
    "            state = self.board.matriz.copy()\n",
    "            avaible_moves = self.board.get_avaible_moves()\n",
    "            action = self.q_agent.choose_move(state,avaible_moves,1)\n",
    "            i, j = self.board.number_ij(action)\n",
    "            self.board.move(i,j,1)\n",
    "            if w != 4:\n",
    "                win_piece = w\n",
    "                break\n",
    "\n",
    "            state = self.board.matriz.copy()\n",
    "            avaible_moves = self.board.get_avaible_moves()\n",
    "            action = self.q_agent.choose_move(state,avaible_moves,2)\n",
    "            i, j = self.board.number_ij(action)\n",
    "            self.board.move(i,j,2)\n",
    "\n",
    "            \n",
    "        return win_piece\n",
    "        \n",
    "    def run_ia_vs_ia(self,n):\n",
    "        games = []\n",
    "        for i in tqdm.tqdm(range(0,n)):\n",
    "            w = self.ia_vs_ia()\n",
    "            games.append(w)\n",
    "        return games\n",
    "    \n",
    "    def ia_vs_user(self):\n",
    "        print('Menu')\n",
    "        print(\"1 - Iniciar aleatorio\")\n",
    "        print(\"2 - Escolher peça [X-O]\")\n",
    "        m1 = int(input())\n",
    "        while m1 != 1 and m1 !=2:\n",
    "            print('Insira um valor valido 1-2')\n",
    "            print(\"1 - Iniciar aleatorio\")\n",
    "            print(\"2 - Escolher peça [X-O]\")\n",
    "            m1 = int(input())\n",
    "\n",
    "        game_over = False\n",
    "        self.board.reset_matrix()\n",
    "        pieces = [1,2]\n",
    "        win_piece = 0\n",
    "        if m1 == 1 :\n",
    "            user = random.choice(pieces)    \n",
    "        else:\n",
    "            print('1 - X \\n 2 - O')\n",
    "            user = int(input())\n",
    "            while user != 1 and user !=2:\n",
    "                print(\"Insira um valor válido 1-2\")\n",
    "                print('1 - X \\n 2 - O')\n",
    "                user = int(input())\n",
    "                \n",
    "\n",
    "        ia = 2 if user == 1 else 1\n",
    "        print(\"Começo de jogo\")\n",
    "        self.board.print_game()\n",
    "        if ia == 1:\n",
    "            while not game_over:\n",
    "                w = self.board.check_win()\n",
    "                if w != 4:\n",
    "                    win_piece = w\n",
    "                    break\n",
    "                state = self.board.matriz.copy()\n",
    "                avaible_moves = self.board.get_avaible_moves()\n",
    "                action = self.q_agent.choose_move(state,avaible_moves,ia)\n",
    "                i, j = self.board.number_ij(action)\n",
    "                print('Jogada da IA - X')\n",
    "                self.board.move(i,j,ia)\n",
    "                self.board.print_game()\n",
    "                if w != 4:\n",
    "                    win_piece = w\n",
    "                    break\n",
    "                print(\"Jogue Usuario - O\")\n",
    "                mv = int(input())\n",
    "                i,j = self.board.number_ij(mv)\n",
    "                self.board.move(i,j,user)\n",
    "                self.board.print_game()\n",
    "\n",
    "        else:\n",
    "             while not game_over:\n",
    "                w = self.board.check_win()\n",
    "                if w != 4:\n",
    "                    win_piece = w\n",
    "                    break\n",
    "\n",
    "                print('Jogue Usuario - X')\n",
    "                mv = int(input())\n",
    "                i,j = self.board.number_ij(mv)\n",
    "                self.board.move(i,j,user)\n",
    "                self.board.print_game()\n",
    "\n",
    "                print('Jogada da IA - O')\n",
    "                state = self.board.matriz.copy()\n",
    "                avaible_moves = self.board.get_avaible_moves()\n",
    "                action = self.q_agent.choose_move(state,avaible_moves,ia)\n",
    "                i, j = self.board.number_ij(action)\n",
    "                self.board.move(i,j,ia)\n",
    "                self.board.print_game()\n",
    "\n",
    "                if w != 4:\n",
    "                    win_piece = w\n",
    "                    break\n",
    "               \n",
    "\n",
    "        if win_piece == ia :\n",
    "            print(\"IA venceu Humano Fraco\")\n",
    "        elif win_piece == user :\n",
    "            print(\"Humano venceu, esta preparado para a revolução?\")\n",
    "        else:\n",
    "            print('Deu velha, mas a I.A segue aprendendo e melhorando e você?')\n",
    "        return win_piece\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing 100 games with X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1525.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing 100 games with O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 2084.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing 100 games ia vs ia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1483.84it/s]\n"
     ]
    }
   ],
   "source": [
    "board = tic_tac_toe_model(3)\n",
    "q_agent = QlearningAgent(alpha=0.1, epsilon=0.5, discount_factor=0.9)\n",
    "exp = train(board,q_agent)\n",
    "n = 100\n",
    "wins_x,wins_o ,wins_ia = exp.run(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IA VS IA\n",
      "IA[X] vs IA[O]\n",
      "Jogos ganhos[x]: 95\n",
      " Jogos perdidos[x]: 5\n",
      " Jogos empatados: 0\n",
      "\n",
      "IA[X] vs Aleatorio \n",
      "Jogos ganhos: 63\n",
      " Jogos perdidos: 28\n",
      " Jogos empatados: 9\n",
      "\n",
      "IA[0] vs Aleatorio \n",
      "Jogos ganhos: 89\n",
      " Jogos perdidos: 11\n",
      " Jogos empatados: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"IA VS IA\")\n",
    "games = np.array(wins_ia)\n",
    "print('IA[X] vs IA[O]')\n",
    "print(f\"Jogos ganhos[x]: {np.where(games==1)[0].shape[0]}\\n\",\n",
    "      f\"Jogos perdidos[x]: {np.where(games==2)[0].shape[0]}\\n\",\n",
    "      f\"Jogos empatados: {np.where(games==3)[0].shape[0]}\\n\")\n",
    "\n",
    "\n",
    "print('IA[X] vs Aleatorio ')\n",
    "games = np.array(wins_x)\n",
    "print(f\"Jogos ganhos: {np.where(games==1)[0].shape[0]}\\n\",\n",
    "      f\"Jogos perdidos: {np.where(games==2)[0].shape[0]}\\n\",\n",
    "      f\"Jogos empatados: {np.where(games==3)[0].shape[0]}\\n\")\n",
    "\n",
    "print('IA[0] vs Aleatorio ')\n",
    "games = np.array(wins_o)\n",
    "print(f\"Jogos ganhos: {np.where(games==1)[0].shape[0]}\\n\",\n",
    "      f\"Jogos perdidos: {np.where(games==2)[0].shape[0]}\\n\",\n",
    "      f\"Jogos empatados: {np.where(games==3)[0].shape[0]}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Game(board, q_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menu\n",
      "1 - Iniciar aleatorio\n",
      "2 - Escolher peça [X-O]\n",
      "1 - X \n",
      " 2 - O\n",
      "Começo de jogo\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "Jogada da IA - X\n",
      "  |   |  \n",
      "---------\n",
      "  | X |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "Jogue Usuario - O\n",
      "O |   |  \n",
      "---------\n",
      "  | X |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "Jogada da IA - X\n",
      "O |   | X\n",
      "---------\n",
      "  | X |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "Jogue Usuario - O\n",
      "O |   | X\n",
      "---------\n",
      "  | X |  \n",
      "---------\n",
      "O |   |  \n",
      "---------\n",
      "Jogada da IA - X\n",
      "O |   | X\n",
      "---------\n",
      "X | X |  \n",
      "---------\n",
      "O |   |  \n",
      "---------\n",
      "Jogue Usuario - O\n",
      "O |   | X\n",
      "---------\n",
      "X | X | O\n",
      "---------\n",
      "O |   |  \n",
      "---------\n",
      "Jogada da IA - X\n",
      "O |   | X\n",
      "---------\n",
      "X | X | O\n",
      "---------\n",
      "O | X |  \n",
      "---------\n",
      "Jogue Usuario - O\n",
      "O |   | X\n",
      "---------\n",
      "X | X | O\n",
      "---------\n",
      "O | X |  \n",
      "---------\n",
      "Jogada da IA - X\n",
      "O | X | X\n",
      "---------\n",
      "X | X | O\n",
      "---------\n",
      "O | X |  \n",
      "---------\n",
      "Jogue Usuario - O\n",
      "O | X | X\n",
      "---------\n",
      "X | X | O\n",
      "---------\n",
      "O | X |  \n",
      "---------\n",
      "IA venceu Humano Fraco\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.ia_vs_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.run_ia_vs_ia(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
