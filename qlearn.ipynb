{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tic_tac_toe_model():\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.matriz = np.full((n,n),0,dtype=int)\n",
    "    \n",
    "    def reset_matrix(self):\n",
    "        self.matriz = np.full((self.n,self.n),0,dtype=int)\n",
    "\n",
    "    def print_game(self):\n",
    "        matriz = self.matriz\n",
    "        substituicoes = {1: \"X\", 2: \"O\", 0:' '}\n",
    "        for linha in matriz:\n",
    "            linha_formatada = [str(substituicoes.get(valor, valor)) for valor in linha]\n",
    "            print(\" | \".join(linha_formatada))\n",
    "            print(\"-\" * 9)\n",
    "    \n",
    "\n",
    "    def number_ij(self, number):\n",
    "        i,j = np.unravel_index(number, self.matriz.shape)\n",
    "        return i,j\n",
    "    \n",
    "    \n",
    "    def get_avaible_moves(self):\n",
    "        avaible_moves = np.ravel_multi_index(np.where(self.matriz == 0), self.matriz.shape)\n",
    "        return list(avaible_moves)\n",
    "\n",
    "    def get_random_move(self, piece):\n",
    "        possible_move_i, possible_move_j = np.where(self.matriz == 0)\n",
    "        if possible_move_j.shape[0] > 0:  # Verifica se há movimentos possíveis\n",
    "            index = random.randint(0, possible_move_j.shape[0] - 1)  # Correção aqui\n",
    "            self.move(possible_move_i[index], possible_move_j[index], piece)\n",
    "\n",
    "\n",
    "\n",
    "    def move(self,index_i,index_j,piece):\n",
    "        if self.matriz[index_i][index_j] == 0:\n",
    "            self.matriz[index_i][index_j] = piece\n",
    "        \n",
    "    \n",
    "    def reward_piece(self,piece):\n",
    "        w = self.check_win()\n",
    "        if w != 4 :\n",
    "            if w!=3:\n",
    "                if w == piece:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return -1\n",
    "            \n",
    "        return 0\n",
    "          \n",
    "    def check_win(self):\n",
    "        state = False\n",
    "        win_piece = -1\n",
    "        value_counts_diagonal = np.unique(self.matriz.diagonal())\n",
    "        value_counts_diagonal2  = np.unique(np.fliplr(self.matriz).diagonal())\n",
    "        if value_counts_diagonal.shape[0] == 1 and value_counts_diagonal[0] !=0:\n",
    "            state=True     \n",
    "            win_piece = value_counts_diagonal[0] \n",
    "            return win_piece          \n",
    "        if value_counts_diagonal2.shape[0] == 1 and value_counts_diagonal2[0] !=0:\n",
    "            state=True    \n",
    "            win_piece = value_counts_diagonal2[0]   \n",
    "            return win_piece         \n",
    "\n",
    "        for i in range(0,self.n):\n",
    "            value_counts_linha = np.unique(self.matriz[i,:])\n",
    "            value_counts_coluna = np.unique(self.matriz[:,i])\n",
    "            \n",
    "            if value_counts_linha.shape[0] == 1 and value_counts_linha[0] != 0 :\n",
    "                state=True\n",
    "                win_piece = value_counts_linha[0]\n",
    "                break\n",
    "            if value_counts_coluna.shape[0] == 1 and value_counts_coluna[0] != 0:\n",
    "                state=True\n",
    "                win_piece = value_counts_coluna[0]\n",
    "                break\n",
    "            \n",
    "        velha = np.where(self.matriz == 0)\n",
    "        \n",
    "        if state:\n",
    "            return win_piece\n",
    "        if velha[0].shape[0] == 0: \n",
    "            return 3\n",
    "        else:\n",
    "            return 4      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QlearningAgent():\n",
    "    def __init__(self, epsilon,alpha ,discount_factor, train):\n",
    "        self.q_table = {}\n",
    "        self.q_table_values = {}\n",
    "        self.q_table_qtd = {}\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.discount_factor = discount_factor\n",
    "        self.train = train\n",
    "\n",
    "         \n",
    "    def get_q_value(self, state, action, piece):\n",
    "        state_tuple = tuple(state.flatten())\n",
    "\n",
    "        if (state_tuple,action,piece) not in self.q_table:\n",
    "            self.q_table[(state_tuple, action, piece)] = 0.0\n",
    "            self.q_table_qtd[(state_tuple, action, piece)] = 0\n",
    "            self.q_table_values[(state_tuple, action, piece)] = 0\n",
    "\n",
    "        return self.q_table[(state_tuple, action, piece)]\n",
    "\n",
    "    def choose_move(self, state, available_moves, piece):\n",
    "        q_values = []\n",
    "        for action in available_moves:\n",
    "            q_values.append(self.get_q_value(state, action, piece))\n",
    "            \n",
    "        if random.uniform(0, 1) < self.epsilon and self.train:\n",
    "            return random.choice(available_moves)\n",
    "        else:\n",
    "            max_q_value = max(q_values)\n",
    "            if q_values.count(max_q_value) > 1:\n",
    "                best_moves = [i for i in range(len(available_moves)) if q_values[i] == max_q_value]\n",
    "                i = random.choice(best_moves)\n",
    "            else:\n",
    "                i = q_values.index(max_q_value)\n",
    "            return available_moves[i]\n",
    "\n",
    "    def update_q_value(self, states, rewards):\n",
    "        #estado atual + alpha[retorno estado atual + ymax(proximo_estado) - estado atual]\n",
    "        for i,state in enumerate(states):\n",
    "            rt = 0\n",
    "            if state not in self.q_table.keys():\n",
    "                self.q_table[state] = 0.0\n",
    "                self.q_table_qtd[state] = 0\n",
    "                self.q_table_values[state] = 0\n",
    "\n",
    "            for ii in range(0,len(rewards)):\n",
    "                rt+= rewards[ii] * (self.discount_factor ** (ii-i))\n",
    "\n",
    "            if i == len(states)-1:\n",
    "                next_reward = 0\n",
    "            else:\n",
    "                next_reward = rewards[i+1]\n",
    "           \n",
    "            q_formula =  self.q_table[state] + (self.alpha*(rewards[i] + self.discount_factor*(next_reward) - self.q_table[state]))\n",
    "            self.q_table[state] = q_formula\n",
    "            #self.q_table_qtd[state] +=1 \n",
    "            #self.q_table[state] = self.q_table_values[state] / self.q_table_qtd[state]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class environment():\n",
    "    def __init__(self, tic_tac_toe: tic_tac_toe_model, q_agent: QlearningAgent, train: bool):\n",
    "        self.board = tic_tac_toe\n",
    "        self.q_agent = q_agent\n",
    "        self.train = train\n",
    "    \n",
    "    def play_one_game(self, piece):\n",
    "        game_over = False\n",
    "        win_piece = 0\n",
    "        self.board.reset_matrix()\n",
    "        if piece == 1:\n",
    "            piece_enemy = 2\n",
    "            states_x = []\n",
    "            rewards_x = []\n",
    "            while not game_over:\n",
    "                w = self.board.check_win()\n",
    "                if w != 4:\n",
    "                    state = self.board.matriz.copy()\n",
    "                    reward_x = self.board.reward_piece(piece)\n",
    "                    state_x = (tuple(state.flatten()),-1,piece)# -1 for terminal state\n",
    "                    states_x.append(state_x)\n",
    "                    rewards_x.append(reward_x)\n",
    "                    win_piece = w\n",
    "                    break\n",
    "\n",
    "                #x move and state/reward/move dynamic\n",
    "                state = self.board.matriz.copy()\n",
    "                avaible_moves = self.board.get_avaible_moves()\n",
    "                action_x = self.q_agent.choose_move(state,avaible_moves,piece)\n",
    "                i, j = self.board.number_ij(action_x)\n",
    "                self.board.move(i,j,piece)\n",
    "                reward_x = self.board.reward_piece(piece)\n",
    "                state_x = (tuple(state.flatten()),action_x,piece)\n",
    "                states_x.append(state_x)\n",
    "                rewards_x.append(reward_x)\n",
    "                w = self.board.check_win()\n",
    "                if w != 4:\n",
    "                    state = self.board.matriz.copy()\n",
    "                    reward_x = self.board.reward_piece(piece)\n",
    "                    state_x = (tuple(state.flatten()),-1,piece)# -1 for terminal state\n",
    "                    states_x.append(state_x)\n",
    "                    rewards_x.append(reward_x)\n",
    "                    win_piece = w\n",
    "                    break\n",
    "                self.board.get_random_move(piece_enemy)\n",
    "               \n",
    "            self.q_agent.update_q_value(states_x,rewards_x)\n",
    "                \n",
    "            return win_piece\n",
    "        else:\n",
    "            piece_enemy = 1\n",
    "            states_o = []\n",
    "            rewards_o = []\n",
    "            while not game_over:\n",
    "                self.board.get_random_move(piece_enemy)\n",
    "               \n",
    "                w = self.board.check_win()  \n",
    "                if w != 4:\n",
    "                    state = self.board.matriz.copy()\n",
    "                    reward_o = self.board.reward_piece(piece)\n",
    "                    state_o = (tuple(state.flatten()),-1,piece)# -1 for terminal state\n",
    "                    states_o.append(state_o)\n",
    "                    rewards_o.append(reward_o)\n",
    "                    win_piece = w\n",
    "                    break\n",
    "                state = self.board.matriz.copy()\n",
    "                avaible_moves = self.board.get_avaible_moves()\n",
    "                action_o = self.q_agent.choose_move(state,avaible_moves,piece)\n",
    "                i, j = self.board.number_ij(action_o)\n",
    "                self.board.move(i,j,piece)\n",
    "                \n",
    "                reward_o = self.board.reward_piece(piece)\n",
    "                state_o = (tuple(state.flatten()), action_o, piece)\n",
    "                states_o.append(state_o)\n",
    "                rewards_o.append(reward_o)\n",
    "                w = self.board.check_win()  \n",
    "                if w != 4:\n",
    "                    state = self.board.matriz.copy()\n",
    "                    reward_o = self.board.reward_piece(piece)\n",
    "                    state_o = (tuple(state.flatten()),-1,piece)# -1 for terminal state\n",
    "                    states_o.append(state_o)\n",
    "                    rewards_o.append(reward_o)\n",
    "                    win_piece = w\n",
    "                    break\n",
    "                 \n",
    "            self.q_agent.update_q_value(states_o,rewards_o)\n",
    "                \n",
    "            return win_piece\n",
    "   \n",
    "            \n",
    "    def play_ia_vs_ia(self):\n",
    "        game_over = False\n",
    "        self.board.reset_matrix()\n",
    "        ia_x = 1\n",
    "        ia_o = 2\n",
    "        states_x = []\n",
    "        rewards_x = []\n",
    "        states_o = []\n",
    "        rewards_o = []\n",
    "        while not game_over:\n",
    "            w = self.board.check_win()\n",
    "            if w != 4:\n",
    "                win_piece = w\n",
    "                break\n",
    "            state_x = self.board.matriz.copy()\n",
    "            avaible_moves_x = self.board.get_avaible_moves()\n",
    "            action_x = self.q_agent.choose_move(state_x,avaible_moves_x,ia_x)\n",
    "            i, j = self.board.number_ij(action_x)\n",
    "            self.board.move(i,j,ia_x) # x play\n",
    "\n",
    "            #x state/reward\n",
    "            reward_x = self.board.reward_piece(ia_x)\n",
    "            state_x = (tuple(state_x.flatten()),action_x,ia_x)\n",
    "            states_x.append(state_x)\n",
    "            rewards_x.append(reward_x)\n",
    "\n",
    "            w = self.board.check_win()\n",
    "            if w != 4:\n",
    "                win_piece = w\n",
    "                break\n",
    "\n",
    "            state_o = self.board.matriz.copy()\n",
    "            avaible_moves_o = self.board.get_avaible_moves()\n",
    "            action_o = self.q_agent.choose_move(state_o,avaible_moves_o,ia_o)\n",
    "            i, j = self.board.number_ij(action_o)\n",
    "            self.board.move(i,j,ia_o) # o play\n",
    "\n",
    "            reward_o = self.board.reward_piece(ia_o)\n",
    "            state_o = (tuple(state_o.flatten()),action_o,ia_o)\n",
    "            states_o.append(state_o)\n",
    "            rewards_o.append(reward_o)\n",
    "        \n",
    "        if win_piece == 1:\n",
    "            state = self.board.matriz.copy()\n",
    "            reward_o = self.board.reward_piece(ia_o)\n",
    "            state_o = (tuple(state.flatten()),-1,ia_o)# -1 for terminal state\n",
    "            states_o.append(state_o)\n",
    "            rewards_o.append(reward_o)     \n",
    "        elif win_piece == 2:\n",
    "            state = self.board.matriz.copy()\n",
    "            reward_x = self.board.reward_piece(ia_x)\n",
    "            state_x = (tuple(state.flatten()),-1,ia_x)# -1 for terminal state\n",
    "            states_x.append(state_x)\n",
    "            rewards_x.append(reward_x)\n",
    "\n",
    "            \n",
    "        self.q_agent.update_q_value(states_x,rewards_x)\n",
    "        self.q_agent.update_q_value(states_o,rewards_o)\n",
    "\n",
    "        return win_piece\n",
    "    \n",
    "    \n",
    "    def run(self, n):\n",
    "        wins_x = []\n",
    "        wins_o = []\n",
    "        wins_ia = []\n",
    "        \n",
    "        print(f'Playing {n} games with X')\n",
    "        for i in tqdm.tqdm(range(0,n)):\n",
    "            wins_x.append(self.play_one_game(piece=1))\n",
    "        \n",
    "        print(f'Playing {n} games with O')\n",
    "        for i in tqdm.tqdm(range(0,n)):\n",
    "            wins_o.append(self.play_one_game(piece=2))\n",
    "            #print(wins_o[i])\n",
    "            #print(\"====================================\")\n",
    "\n",
    "        print(f'Playing {n} games ia vs ia')\n",
    "        for i in tqdm.tqdm(range(0,n)):\n",
    "            wins_ia.append(self.play_ia_vs_ia())\n",
    "        \n",
    "        return wins_x,wins_o, wins_ia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game():\n",
    "    def __init__(self, tic_tac_toe: tic_tac_toe_model, q_agent: QlearningAgent):\n",
    "        self.board = tic_tac_toe\n",
    "        self.q_agent = q_agent\n",
    "    \n",
    "\n",
    "    def ia_vs_ia(self):\n",
    "        game_over = False\n",
    "        self.board.reset_matrix()\n",
    "        while not game_over:\n",
    "            w = self.board.check_win()\n",
    "            if w != 4:\n",
    "                win_piece = w\n",
    "                break\n",
    "            state = self.board.matriz.copy()\n",
    "            avaible_moves = self.board.get_avaible_moves()\n",
    "            action = self.q_agent.choose_move(state,avaible_moves,1)\n",
    "            i, j = self.board.number_ij(action)\n",
    "            self.board.move(i,j,1)\n",
    "            if w != 4:\n",
    "                win_piece = w\n",
    "                break\n",
    "\n",
    "            state = self.board.matriz.copy()\n",
    "            avaible_moves = self.board.get_avaible_moves()\n",
    "            action = self.q_agent.choose_move(state,avaible_moves,2)\n",
    "            i, j = self.board.number_ij(action)\n",
    "            self.board.move(i,j,2)\n",
    "\n",
    "            \n",
    "        return win_piece\n",
    "        \n",
    "    def run_ia_vs_ia(self,n):\n",
    "        games = []\n",
    "        for i in tqdm.tqdm(range(0,n)):\n",
    "            w = self.ia_vs_ia()\n",
    "            games.append(w)\n",
    "        return games\n",
    "    \n",
    "    def ia_vs_user(self):\n",
    "        print('Menu')\n",
    "        print(\"1 - Iniciar aleatorio\")\n",
    "        print(\"2 - Escolher peça [X-O]\")\n",
    "        m1 = int(input())\n",
    "        while m1 != 1 and m1 !=2:\n",
    "            print('Insira um valor valido 1-2')\n",
    "            print(\"1 - Iniciar aleatorio\")\n",
    "            print(\"2 - Escolher peça [X-O]\")\n",
    "            m1 = int(input())\n",
    "\n",
    "        game_over = False\n",
    "        self.board.reset_matrix()\n",
    "        pieces = [1,2]\n",
    "        win_piece = 0\n",
    "        if m1 == 1 :\n",
    "            user = random.choice(pieces)    \n",
    "        else:\n",
    "            print('1 - X \\n 2 - O')\n",
    "            user = int(input())\n",
    "            while user != 1 and user !=2:\n",
    "                print(\"Insira um valor válido 1-2\")\n",
    "                print('1 - X \\n 2 - O')\n",
    "                user = int(input())\n",
    "                \n",
    "\n",
    "        ia = 2 if user == 1 else 1\n",
    "        print(\"Começo de jogo\")\n",
    "        self.board.print_game()\n",
    "        if ia == 1:\n",
    "            while not game_over:\n",
    "                w = self.board.check_win()\n",
    "                if w != 4:\n",
    "                    win_piece = w\n",
    "                    break\n",
    "                state = self.board.matriz.copy()\n",
    "                avaible_moves = self.board.get_avaible_moves()\n",
    "                action = self.q_agent.choose_move(state,avaible_moves,ia)\n",
    "                i, j = self.board.number_ij(action)\n",
    "                print('Jogada da IA - X')\n",
    "                self.board.move(i,j,ia)\n",
    "                self.board.print_game()\n",
    "                if w != 4:\n",
    "                    win_piece = w\n",
    "                    break\n",
    "                print(\"Jogue Usuario - O\")\n",
    "                mv = int(input())\n",
    "                i,j = self.board.number_ij(mv)\n",
    "                self.board.move(i,j,user)\n",
    "                self.board.print_game()\n",
    "\n",
    "        else:\n",
    "             while not game_over:\n",
    "                w = self.board.check_win()\n",
    "                if w != 4:\n",
    "                    win_piece = w\n",
    "                    break\n",
    "\n",
    "                print('Jogue Usuario - X')\n",
    "                mv = int(input())\n",
    "                i,j = self.board.number_ij(mv)\n",
    "                self.board.move(i,j,user)\n",
    "                self.board.print_game()\n",
    "\n",
    "                print('Jogada da IA - O')\n",
    "                state = self.board.matriz.copy()\n",
    "                avaible_moves = self.board.get_avaible_moves()\n",
    "                action = self.q_agent.choose_move(state,avaible_moves,ia)\n",
    "                i, j = self.board.number_ij(action)\n",
    "                self.board.move(i,j,ia)\n",
    "                self.board.print_game()\n",
    "\n",
    "                if w != 4:\n",
    "                    win_piece = w\n",
    "                    break\n",
    "               \n",
    "\n",
    "        if win_piece == ia :\n",
    "            print(\"IA venceu Humano Fraco\")\n",
    "        elif win_piece == user :\n",
    "            print(\"Humano venceu, esta preparado para a revolução?\")\n",
    "        else:\n",
    "            print('Deu velha, mas a I.A segue aprendendo e melhorando e você?')\n",
    "        return win_piece\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing 100000 games with X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:06<00:00, 1492.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing 100000 games with O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:00<00:00, 1661.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing 100000 games ia vs ia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:27<00:00, 1149.38it/s]\n"
     ]
    }
   ],
   "source": [
    "board = tic_tac_toe_model(3)\n",
    "q_agent = QlearningAgent(epsilon=0.9, alpha=0.6,discount_factor=1, train=True)\n",
    "exp = environment(board,q_agent, train=True)\n",
    "n = 100000\n",
    "wins_x,wins_o, wins_ia = exp.run(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18083"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q_agent.q_table.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IA VS IA\n",
      "IA[X] vs IA[O]\n",
      "Jogos ganhos[x]: 58.449%\n",
      " Jogos perdidos[x]: 30.045%\n",
      " Jogos empatados: 11.506%\n",
      "\n",
      "IA[X] vs Aleatorio \n",
      "Jogos ganhos: 63.105%\n",
      " Jogos perdidos: 25.458%\n",
      " Jogos empatados: 11.437%\n",
      "\n",
      "IA[0] vs Aleatorio \n",
      "Jogos ganhos: 33.266%\n",
      " Jogos perdidos: 54.173%\n",
      " Jogos empatados: 12.561%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"IA VS IA\")\n",
    "games = np.array(wins_ia)\n",
    "print('IA[X] vs IA[O]')\n",
    "print(f\"Jogos ganhos[x]: {np.where(games==1)[0].shape[0]*100/n}%\\n\",\n",
    "      f\"Jogos perdidos[x]: {np.where(games==2)[0].shape[0]*100/n}%\\n\",\n",
    "      f\"Jogos empatados: {np.where(games==3)[0].shape[0]*100/n}%\\n\")\n",
    "\n",
    "print('IA[X] vs Aleatorio ')\n",
    "games = np.array(wins_x)\n",
    "print(f\"Jogos ganhos: {np.where(games==1)[0].shape[0]*100/n}%\\n\",\n",
    "      f\"Jogos perdidos: {np.where(games==2)[0].shape[0]*100/n}%\\n\",\n",
    "      f\"Jogos empatados: {np.where(games==3)[0].shape[0]*100/n}%\\n\")\n",
    "\n",
    "print('IA[0] vs Aleatorio ')\n",
    "games = np.array(wins_o)\n",
    "print(f\"Jogos ganhos: {np.where(games==2)[0].shape[0]*100/n}%\\n\",\n",
    "      f\"Jogos perdidos: {np.where(games==1)[0].shape[0]*100/n}%\\n\",\n",
    "      f\"Jogos empatados: {np.where(games==3)[0].shape[0]*100/n}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing 1000 games with X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2075.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing 1000 games with O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1957.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing 1000 games ia vs ia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1149.64it/s]\n"
     ]
    }
   ],
   "source": [
    "q_agent.epsilon = 0\n",
    "q_agent.train = False\n",
    "\n",
    "n = 1000\n",
    "wins_x,wins_o, wins_ia = exp.run(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IA VS IA\n",
      "IA[X] vs IA[O]\n",
      "Jogos ganhos[x]: 41.7%\n",
      " Jogos perdidos[x]: 29.8%\n",
      " Jogos empatados: 28.5%\n",
      "\n",
      "IA[X] vs Aleatorio \n",
      "Jogos ganhos: 97.1%\n",
      " Jogos perdidos: 1.7%\n",
      " Jogos empatados: 1.2%\n",
      "\n",
      "IA[0] vs Aleatorio \n",
      "Jogos ganhos: 80.5%\n",
      " Jogos perdidos: 9.2%\n",
      " Jogos empatados: 10.3%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"IA VS IA\")\n",
    "games = np.array(wins_ia)\n",
    "print('IA[X] vs IA[O]')\n",
    "print(f\"Jogos ganhos[x]: {np.where(games==1)[0].shape[0]*100/n}%\\n\",\n",
    "      f\"Jogos perdidos[x]: {np.where(games==2)[0].shape[0]*100/n}%\\n\",\n",
    "      f\"Jogos empatados: {np.where(games==3)[0].shape[0]*100/n}%\\n\")\n",
    "\n",
    "print('IA[X] vs Aleatorio ')\n",
    "games = np.array(wins_x)\n",
    "print(f\"Jogos ganhos: {np.where(games==1)[0].shape[0]*100/n}%\\n\",\n",
    "      f\"Jogos perdidos: {np.where(games==2)[0].shape[0]*100/n}%\\n\",\n",
    "      f\"Jogos empatados: {np.where(games==3)[0].shape[0]*100/n}%\\n\")\n",
    "\n",
    "print('IA[0] vs Aleatorio ')\n",
    "games = np.array(wins_o)\n",
    "print(f\"Jogos ganhos: {np.where(games==2)[0].shape[0]*100/n}%\\n\",\n",
    "      f\"Jogos perdidos: {np.where(games==1)[0].shape[0]*100/n}%\\n\",\n",
    "      f\"Jogos empatados: {np.where(games==3)[0].shape[0]*100/n}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Game(board, q_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game.ia_vs_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game.run_ia_vs_ia(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
